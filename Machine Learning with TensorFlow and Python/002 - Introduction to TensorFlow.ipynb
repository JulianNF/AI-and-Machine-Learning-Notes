{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine Learning with Tensor and Python\n",
    "===\n",
    "\n",
    "These are JulianNF's notes from following [freecodecamp's online Machine Learning with Python certification](https://www.freecodecamp.org/learn/machine-learning-with-python), and supplemented by [Google's Tensorflow documentation](https://www.tensorflow.org/guide/tensor)\n",
    "\n",
    "Feel free to benefit from them if you're studying on your own.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to tensors in TensorFlow\n",
    "\n",
    "A tensor is, ‚Äú**A generalization of vectors and matrices to potentially higher dimensions**‚Äù\n",
    "\n",
    "Why a vector? --> Because it can have lots of ‚Äúdimensions‚Äù, each dimension being an additional related value.\n",
    "\n",
    "In tensorflow, tensors are represented as n-dimensional arrays of base datatypes. Each tensor represents a partially defined computation that will eventually produce a value.\n",
    "\n",
    "Each tensor has a certain \"dimensionality\", which reflects its complexity. The number of dimensions of a tensor is defined by its **rank** (aka **degree**). A tensor with one value has a rank/degree of zero (0), and is also called a ‚Äúscalar‚Äù. For example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stringTensor = tf.Variable(\"this is a string\", tf.string)\n",
    "numberTensor = tf.Variable(124, tf.int16)\n",
    "floatTensor = tf.Variable(3.456, tf.float64)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimension / Rank / Degree\n",
    "Denotes the relative complexity of the structure of the tensor.\n",
    "\n",
    "Tensors with two dimensions/ranks/degrees are known as a **vector**.\n",
    "\n",
    "Tensors with 2 ranks have two axes and are referred to as a **\"matrix\"**. It's basically a nested list, and as such, a tensor can have an arbitrarily large number of axes.\n",
    "\n",
    "![visualisations of 3-axis tensor](img\\google-visualizing_tensors_with_multiple_axes.jpg)\n",
    "\n",
    "We can determine the rank/degree of any tensor with `.rank()` and see that numpy reports a rank/degree of 0 for our scalar tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.rank(stringTensor))\n",
    "\n",
    "\n",
    "tensorWithRank1 = tf.Variable(\n",
    "    [\"Test\", \"Ok\", \"Tim\"],\n",
    "    tf.string\n",
    ")\n",
    "tensorWithRank2 = tf.Variable(\n",
    "    [\n",
    "        [\"test\", \"ok\"],\n",
    "        [\"test\", \"yes\"],\n",
    "        [\"3rd\", \"element\"],\n",
    "    ],\n",
    "    tf.string\n",
    ")\n",
    "\n",
    "# expect numpy = 2 because tensor has a list within a list\n",
    "print(tf.rank(tensorWithRank2))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the metadata of a tensor\n",
    "\n",
    "Tensors have a number of methods that we can use to determine their shape, dimension/rank, etc:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of every element in tensor: <dtype: 'float32'>\n",
      "Number of axes/dimensions in tensor: 4\n",
      "Elements in first axis of tensor: 3\n",
      "Elements in last axis of tensor: 5\n",
      "Total number of elements in the tensor: 120\n",
      "\n",
      "Type of every element in tensor: tf.Tensor(4, shape=(), dtype=int32)\n",
      "Number of axes/dimensions in tensor: tf.Tensor([], shape=(0,), dtype=int32)\n",
      "Total number of elements in the tensor: tf.Tensor(120, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "rank_4_tensor = tf.zeros([3,2,4,5])\n",
    "\n",
    "# Returning values:\n",
    "print('Type of every element in tensor:', rank_4_tensor.dtype)\n",
    "print('Number of axes/dimensions in tensor:', rank_4_tensor.ndim)\n",
    "print('Elements in first axis of tensor:', rank_4_tensor.shape[0])\n",
    "print('Elements in last axis of tensor:', rank_4_tensor.shape[-1])\n",
    "print('Total number of elements in the tensor:', tf.size(rank_4_tensor).numpy())\n",
    "\n",
    "# Returning objects:\n",
    "print('\\nType of every element in tensor:', tf.rank(rank_4_tensor))\n",
    "print('Number of axes/dimensions in tensor:', tf.shape(rank_4_tensor.ndim))\n",
    "print('Total number of elements in the tensor:', tf.size(rank_4_tensor))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting a tensor to a list\n",
    "As simple as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 2, 4, 5]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_4_tensor.shape.as_list()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor shape\n",
    "\n",
    "Defines the size of each dimension of the tensor.\n",
    "\n",
    "As a memory aid, to keep track of which axis contains what types of data, as tensors get more complex:\n",
    "\n",
    "![typical tensor axis order](img\\google-typical_tensor_axis_order.jpg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing a tensor's shape (aka reshaping)\n",
    "\n",
    "The **size** of a tensor is the total number of elements in said tensor. The quickest way to think of it is as the product of the sizes of all its shapes (e.g. 3 lists x 2 elements/list = 6 elements).\n",
    "\n",
    "If different tensors have the same number of elements, we can \"reshape\" the tensor (i.e. rearrange the elements). This operation is fast and cheap as the underlying data does not need to be duplicated. The data maintains its layout in memory, and a new tensor is created with the requested shape, pointing to the same data.\n",
    "\n",
    "Typically the only reasonable use of `tf.reshape` is to combine or split adjacent axes (e.g. (3x2)x5 --> 3x(2x5)) (or add/remove 1s).\n",
    "\n",
    "\n",
    "For example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[1. 1. 1.]\n",
      "  [1. 1. 1.]]], shape=(1, 2, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[1.]\n",
      "  [1.]\n",
      "  [1.]]\n",
      "\n",
      " [[1.]\n",
      "  [1.]\n",
      "  [1.]]], shape=(2, 3, 1), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]], shape=(3, 2), dtype=float32)\n",
      "tf.Tensor([1. 1. 1. 1. 1. 1.], shape=(6,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# tf.ones() creates a tensor with a shape [1,2,3] (total of 6 elements) where each element is a one\n",
    "# tf.zeroes() also exists\n",
    "tensor1 = tf.ones([1,2,3])\n",
    "print(tensor1)\n",
    "\n",
    "# reshape the tensor to a shape of [2,3,1] (total elements = original size of tensor)\n",
    "tensor2 = tf.reshape(tensor1, [2,3,1])\n",
    "print(tensor2)\n",
    "\n",
    "# -1 tells the tensor to calculate/infer the size of the dimension in that layer so that all the elements in the original tensor are accounted for --> in this case, it'll reshape the tensor to [3,2]\n",
    "tensor3 = tf.reshape(tensor1, [3,-1])\n",
    "print(tensor3)\n",
    "\n",
    "# Flatten a tensor entirely to one vector, which will show the order of the elements in memory:\n",
    "tensor3 = tf.reshape(tensor1, [-1])\n",
    "print(tensor3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting tensors to numpy arrays\n",
    "\n",
    "To convert a tensor to a numpy array, simply use `np.array` or `tensor/numpy()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1.]\n",
      "  [1.]\n",
      "  [1.]]\n",
      "\n",
      " [[1.]\n",
      "  [1.]\n",
      "  [1.]]]\n",
      "[[[1.]\n",
      "  [1.]\n",
      "  [1.]]\n",
      "\n",
      " [[1.]\n",
      "  [1.]\n",
      "  [1.]]]\n"
     ]
    }
   ],
   "source": [
    "numpyArray1 = np.array(tensor2)\n",
    "print(numpyArray1)\n",
    "\n",
    "numpyArray2 = tensor2.numpy()\n",
    "print(numpyArray2)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing math on tensors\n",
    "\n",
    "Like with regular arrays, mathematical operations can be performed on tensors and their elements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[2 3]\n",
      " [4 5]], shape=(2, 2), dtype=int32) \n",
      "\n",
      "tf.Tensor(\n",
      "[[1 2]\n",
      " [3 4]], shape=(2, 2), dtype=int32) \n",
      "\n",
      "tf.Tensor(\n",
      "[[3 3]\n",
      " [7 7]], shape=(2, 2), dtype=int32) \n",
      "\n",
      "tf.Tensor(\n",
      "[[2 3]\n",
      " [4 5]], shape=(2, 2), dtype=int32) \n",
      "\n",
      "tf.Tensor(\n",
      "[[1 2]\n",
      " [3 4]], shape=(2, 2), dtype=int32) \n",
      "\n",
      "tf.Tensor(\n",
      "[[3 3]\n",
      " [7 7]], shape=(2, 2), dtype=int32) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "firstTensor = tf.constant(\n",
    "    [\n",
    "        [1, 2],\n",
    "        [3, 4]\n",
    "    ]\n",
    ")\n",
    "secondTensor = tf.constant(\n",
    "    [\n",
    "        [1, 1],\n",
    "        [1, 1]\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(tf.add(firstTensor, secondTensor), '\\n')\n",
    "print(tf.multiply(firstTensor, secondTensor), '\\n')\n",
    "print(tf.matmul(firstTensor, secondTensor), '\\n')\n",
    "\n",
    "print(firstTensor + secondTensor, '\\n') # element-wise addition\n",
    "print(firstTensor * secondTensor, '\\n') # element-wise multiplication\n",
    "print(firstTensor @ secondTensor, '\\n') # matrix multiplication"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operations (aka Ops)\n",
    "Tensors are used in all kinds of operations (aka **Ops**):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(10.0, shape=(), dtype=float32)\n",
      "tf.Tensor([1 0], shape=(2,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[2.6894143e-01 7.3105860e-01]\n",
      " [9.9987662e-01 1.2339458e-04]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "anotherTensor = tf.constant(\n",
    "\t[\n",
    "\t\t[4.0, 5.0],\n",
    "\t\t[10.0, 1.0]\n",
    "\t]\n",
    ")\n",
    "\n",
    "#  Find the largest value:\n",
    "print(tf.reduce_max(anotherTensor))\n",
    "# Find the index of the largest value:\n",
    "print(tf.math.argmax(anotherTensor))\n",
    "# Compute the softmax:\n",
    "print(tf.nn.softmax(anotherTensor))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that tensor also refers to method such as `reshape` as an operation."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Broadcasting\n",
    "Like with Numpy arrays, when performing matrix operations, under certain circumstances, Tensorflow will expand the tensors so that their column and row sizes match, in order to allow the math operation to work\n",
    "\n",
    "Most of the time, broadcasting is both time and space efficient, as the broadcast operation never materializes the expanded tensors in memory. Note however that `tf.broadcast_to()` does nothing special to save memory, and materialzies the tensor.\n",
    "\n",
    "üß†üìñ For more info on broadcasting in Python, see Jake VanderPlas' book [_Python Data Science Handbook_](https://jakevdp.github.io/PythonDataScienceHandbook/02.05-computation-on-arrays-broadcasting.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([3 6 9], shape=(3,), dtype=int32)\n",
      "tf.Tensor([3 6 9], shape=(3,), dtype=int32)\n",
      "tf.Tensor([3 6 9], shape=(3,), dtype=int32)\n",
      "\n",
      " tf.Tensor(\n",
      "[[1]\n",
      " [2]\n",
      " [3]], shape=(3, 1), dtype=int32)\n",
      "tf.Tensor([1 2 3 4], shape=(4,), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[ 1  2  3  4]\n",
      " [ 2  4  6  8]\n",
      " [ 3  6  9 12]], shape=(3, 4), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "scalar = tf.constant(3)\n",
    "vector1 = tf.constant([1,2,3])\n",
    "vector2 = tf.constant([3,3,3]) # equivalent to 'scalar' if it was broadcast to the size of vector1\n",
    "\n",
    "print(tf.multiply(vector1, scalar))\n",
    "print(vector1 * scalar)\n",
    "print(vector1 * vector2)\n",
    "\n",
    "# Another example:\n",
    "vector1a = tf.reshape(vector1, [3,1])\n",
    "print('\\n', vector1a)\n",
    "vector2a = tf.range(1,5)\n",
    "print(vector2a)\n",
    "print(tf.multiply(vector1a, vector2a))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing data in tensors\n",
    "\n",
    "Tensor data is zero-index and behaves like a Python list. To access the desired data, use indeces as you would in Python, including using `:` for slicing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "5\n",
      "21\n",
      "[0 1 2 3]\n",
      "[ 5  8 21 34]\n",
      "[21 34]\n",
      "[ 3 21]\n",
      "[]\n",
      "[ 0  2  5 21]\n",
      "\n",
      "\n",
      "6.2\n",
      "[3.5 6.2]\n",
      "[1. 2.]\n",
      "2.0\n",
      "\n",
      "\n",
      "[[  6.2    55.6  ]\n",
      " [432.    212.5  ]\n",
      " [ 78.     95.687]]\n",
      "55.6\n",
      "[[ 3.5  6.2]\n",
      " [-3.  55.6]]\n",
      "[16. 78.]\n",
      "212.5\n"
     ]
    }
   ],
   "source": [
    "# Vectors:\n",
    "simpleTensor = tf.constant([0,1,2,3,5,8,21,34])\n",
    "print(simpleTensor[0].numpy())\n",
    "print(simpleTensor[4].numpy())\n",
    "print(simpleTensor[-2].numpy())\n",
    "\n",
    "print(simpleTensor[:4].numpy())\n",
    "print(simpleTensor[4:].numpy())\n",
    "print(simpleTensor[6:8].numpy())\n",
    "print(simpleTensor[3:9:3].numpy())\n",
    "print(simpleTensor[3:9:-1].numpy())\n",
    "print(simpleTensor[::2].numpy())\n",
    "\n",
    "# 2nd-degree matrices:\n",
    "rank_2_tensor = tf.constant(\n",
    "    [\n",
    "        [3.5, 6.2],\n",
    "        [1, 2]\n",
    "    ]\n",
    ")\n",
    "\n",
    "print('\\n')\n",
    "print(rank_2_tensor[0, 1].numpy())\n",
    "print(rank_2_tensor[0, :].numpy())\n",
    "print(rank_2_tensor[-1, :].numpy())\n",
    "print(rank_2_tensor[1, -1].numpy())\n",
    "\n",
    "# 3rd-degree matrices:\n",
    "rank_3_tensor = tf.constant(\n",
    "    [\n",
    "        [\n",
    "            [3.5, 6.2],\n",
    "            [-3, 55.6]\n",
    "        ],\n",
    "        [\n",
    "            [12, 432],\n",
    "            [1, 212.5]\n",
    "        ],\n",
    "        [\n",
    "            [16, 78],\n",
    "            [66, 95.687]\n",
    "        ]\n",
    "    ]\n",
    ")\n",
    "\n",
    "print('\\n')\n",
    "print(rank_3_tensor[:, :, 1].numpy())\n",
    "print(rank_3_tensor[0, 1, 1].numpy())\n",
    "print(rank_3_tensor[0, :, :].numpy())\n",
    "print(rank_3_tensor[-1, 0, :].numpy())\n",
    "print(rank_3_tensor[1, -1, -1].numpy())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using other objects with tensor methods\n",
    "\n",
    "Typically, Tensorflow can handle using valid inputs that are not tensors. Note that if you don't pass a datatype (optional), Tensor will infer a datatype that works for all the data\n",
    "- python integers --> tf.int32\n",
    "- python floats --> tf.float32\n",
    "\n",
    "‚ÜóÔ∏è Most (but not all) ops call `tf.convert_to_tensor` on non-tensor arguments. There's a registry of conversions and most object classes will convert automatically. To add you own types, check out `tf.register_tensor_conversion_function`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=3>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.convert_to_tensor([1,2,3])\n",
    "tf.convert_to_tensor([1,2,3], dtype=tf.float64)\n",
    "tf.reduce_max([1,2,3])\n",
    "tf.reduce_max(np.array([1,2,3]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Casting tensor element datatypes\n",
    "\n",
    "You can cast the `dtype` of a tensor to another datatype:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([2.23456789 3.3        4.4       ], shape=(3,), dtype=float64)\n",
      "tf.Tensor([2.234 3.3   4.4  ], shape=(3,), dtype=float16)\n",
      "tf.Tensor([2 3 4], shape=(3,), dtype=uint8)\n"
     ]
    }
   ],
   "source": [
    "f64_tensor = tf.constant([2.23456789, 3.3, 4.4], dtype=tf.float64)\n",
    "print(f64_tensor)\n",
    "f16_tensor = tf.cast(f64_tensor, dtype=tf.float16)\n",
    "print(f16_tensor)\n",
    "\n",
    "u8_tensor = tf.cast(f16_tensor, dtype=tf.uint8) # lose all decimal precision\n",
    "print(u8_tensor)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of tensors\n",
    "\n",
    "There are many types of tensors. The most common ones are:\n",
    "\n",
    "1. Variable\n",
    "2. Constant\n",
    "3. Placeholder\n",
    "4. SparseTensor\n",
    "\n",
    "With the exception of Variable tensors, the other tensors are immutable, in that their value cannot change during execution.\n",
    "\n",
    "The base `tf.Tensor` class requires tensors to be \"rectangular\", that is, every element along an axis must be the same size (i.e. type). Nevertheless, there are some specialized tensors that can handle different shapes:\n",
    "- ragged tensors\n",
    "- sparse tensors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ragged Tensors\n",
    "\n",
    "Tensors with inconsistent axis sizes (at the same parent level) as referred to as \"**ragged**\". When working with such data, use `tf.ragged.RaggedTensor`.\n",
    "\n",
    "![ragged tensor depiction](img\\google-ragged_tensor_image.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ValueError: Can't convert non-rectangular Python sequence to Tensor.\n",
      "<tf.RaggedTensor [[0, 1, 2, 3], [4, 5], [6, 7, 8], [9]]>\n",
      "(4, None)\n"
     ]
    }
   ],
   "source": [
    "ragged_list = [\n",
    "\t[0,1,2,3],\n",
    "\t[4,5],\n",
    "\t[6,7,8],\n",
    "\t[9]\n",
    "]\n",
    "\n",
    "try:\n",
    "\ttensor = tf.constant(ragged_list)\n",
    "except Exception as e:\n",
    "\tprint(f\"{type(e).__name__}: {e}\")\n",
    "\n",
    "ragged_tensor = tf.ragged.constant(ragged_list)\n",
    "print(ragged_tensor)\n",
    "print(ragged_tensor.shape) # note how the length of the second axis is unknown"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### String Tensors\n",
    "\n",
    "Strings in Tensorflow are stored as variable-length byte arrays (not a unicode string).\n",
    "\n",
    "It's important to not that string tensors are atomic -- you cannot access characters via index. As such, **the length of the string is not one of the axes of the tensor**. In order words, when considering strings, Tensor ignores the length of each entry.\n",
    "\n",
    "See `tf.strings` for functions to manipulate strings in Tensor.\n",
    "\n",
    "A string tensor can be split into more tensors, but be aware that this will likely result in a ragged tensor, as the lengths and splitting-characters of each string might not be the same across the strings in the original tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([b'Gray wolf pup' b'Chocolate lab' b'Kangaroo'], shape=(3,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "string_tensor = tf.constant(\n",
    "\t[\n",
    "\t\t\"Gray wolf pup\",\n",
    "\t\t\"Chocolate lab\",\n",
    "\t\t\"Kangaroo\"\n",
    "\t]\n",
    ")\n",
    "\n",
    "print(string_tensor) # note how no length is reported in the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[b'Gray', b'wolf', b'pup'], [b'Chocolate', b'lab'], [b'Kangaroo']]>\n"
     ]
    }
   ],
   "source": [
    "print(tf.strings.split(string_tensor, sep=''))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparse Tensors\n",
    "\n",
    "![sparse tensor image](img\\google-sparse_tensor_image.png)\n",
    "\n",
    "Sometimes the data is missing lots of entries. For this, we can use sparse tensors. These store values by index, rather than having a bunch of empty spots in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1 0 0 0]\n",
      " [0 0 2 0]\n",
      " [0 0 0 0]], shape=(3, 4), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "sparse_tensor = tf.sparse.SparseTensor(\n",
    "\tindices=[\n",
    "\t\t[0,0],\n",
    "\t\t[1,2]\n",
    "\t],\n",
    "\tvalues= [1, 2 ],\n",
    "\tdense_shape=[3,4]\n",
    ")\n",
    "# convert sparse tensor to dense (i.e. full) and print\n",
    "print(tf.sparse.to_dense(sparse_tensor))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Tensors\n",
    "\n",
    "Remember that tensors represent a partially complete computation. We will sometimes need to run a **session** in order to evaluate a tensor. There are many ways to get the value of a tensor, the simples being:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'Session'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16128\\3208742295.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m         \u001b[0mtensor3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'Session'"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "\ttensor3.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c4b873e07bceb12c2b9a42b36e7722015039dfeed477cfe3ebf1d2c97eb81cf7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
