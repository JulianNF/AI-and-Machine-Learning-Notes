{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine Learning with Tensor and Python\n",
    "===\n",
    "\n",
    "These are JulianNF's notes from following [freecodecamp's online Machine Learning with Python certification](https://www.freecodecamp.org/learn/machine-learning-with-python), and supplemented by [Google's Tensorflow documentation](https://www.tensorflow.org/guide/tensor)\n",
    "\n",
    "Feel free to benefit from them if you're studying on your own.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%tensorflow_version` not found.\n"
     ]
    }
   ],
   "source": [
    "# Required in notebook:\n",
    "%pip install -q sklearn\n",
    "%tensorflow_version 2.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import pandas as pd # library for data manipulation\n",
    "# import numpy as np # library for handling arrays better\n",
    "# import matplotlib.pyplot as plt # library for graphing\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Data prepared in previous module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VocabularyListCategoricalColumn(key='sex', vocabulary_list=('male', 'female'), dtype=tf.string, default_value=-1, num_oov_buckets=0), VocabularyListCategoricalColumn(key='n_siblings_spouses', vocabulary_list=(1, 0, 3, 4, 2, 5, 8), dtype=tf.int64, default_value=-1, num_oov_buckets=0), VocabularyListCategoricalColumn(key='parch', vocabulary_list=(0, 1, 2, 5, 3, 4), dtype=tf.int64, default_value=-1, num_oov_buckets=0), VocabularyListCategoricalColumn(key='class', vocabulary_list=('Third', 'First', 'Second'), dtype=tf.string, default_value=-1, num_oov_buckets=0), VocabularyListCategoricalColumn(key='deck', vocabulary_list=('unknown', 'C', 'G', 'A', 'B', 'D', 'F', 'E'), dtype=tf.string, default_value=-1, num_oov_buckets=0), VocabularyListCategoricalColumn(key='embark_town', vocabulary_list=('Southampton', 'Cherbourg', 'Queenstown', 'unknown'), dtype=tf.string, default_value=-1, num_oov_buckets=0), VocabularyListCategoricalColumn(key='alone', vocabulary_list=('n', 'y'), dtype=tf.string, default_value=-1, num_oov_buckets=0), NumericColumn(key='age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='fare', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]\n"
     ]
    }
   ],
   "source": [
    "training_dataframe = pd.read_csv(\t'https://storage.googleapis.com/tf-datasets/titanic/train.csv')\n",
    "testing_dataframe = pd.read_csv(\t'https://storage.googleapis.com/tf-datasets/titanic/eval.csv')\n",
    "\n",
    "training_survived = training_dataframe.pop('survived')\n",
    "testing_survived = testing_dataframe.pop('survived')\n",
    "\n",
    "CATEGORICAL_COLUMNS = [\n",
    "\t'sex',\n",
    "\t'n_siblings_spouses',\n",
    "\t'parch',\n",
    "\t'class',\n",
    "\t'deck',\n",
    "\t'embark_town',\n",
    "\t'alone'\n",
    "]\n",
    "\n",
    "NUMERIC_COLUMNS = [\n",
    "\t'age',\n",
    "\t'fare'\n",
    "]\n",
    "\n",
    "feature_columns = []\n",
    "\n",
    "for feature_name in CATEGORICAL_COLUMNS:\n",
    "\tvocabulary = training_dataframe[feature_name].unique() # get all unique possible values (aka categories) in the given column\n",
    "\tfeature_columns.append(\n",
    "\t\ttf.feature_column.categorical_column_with_vocabulary_list(feature_name, vocabulary)\n",
    "\t)\n",
    "# print(feature_columns)\n",
    "\n",
    "for feature_name in NUMERIC_COLUMNS:\n",
    "\tfeature_columns.append(\n",
    "\t\ttf.feature_column.numeric_column(feature_name, dtype=tf.float32)\n",
    "\t)\n",
    "print(feature_columns)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batches\n",
    "Typically, the size of our datasets is quite large, and most training processes would not be able to run all the data at once on RAM. We therefore feed our data to our model in smaller batches.\n",
    "\n",
    "In this course, we're going to load the data in batches of 32 data points. Notes that feeding data to our model 1 data point at a time would actually be slower than doing it in \"bit size chunks\"."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Epochs\n",
    "As we feed more and more batches of data into our model, it will improve. However, we need to feed the data multiple times so that the model can process all data points alongside all the other data points. \n",
    "\n",
    "‚ùìTBC - sounds like the number of epochs is related to all the permutations required so that all the data points have been processed alongside all the other datapoints.\n",
    "\n",
    "Each epoch is therefore equal to one complete stream of our data. The number of epochs we feed into our model will be equal to the number of times that our model sees the complete data set.\n",
    "\n",
    "‚ùìTBC - An epoch is therefore \"one round of training\"?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Function\n",
    "Before we start training our model, we need to convert our Pandas dataframe into a TensorFlow dataset (`tf.data.Dataset`). To do this, we need to create an input function, whose job it will be to handle the conversion.\n",
    "\n",
    "Here's an example from the TensorFlow documentation, which we'll be using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_input_function(data_dataframe, label_dataframe, num_epochs=10, shuffle=True, batch_size=32):\n",
    "\tdef input_function():\n",
    "\t\t# Create a labeled TF dataset from our dataframe:\n",
    "\t\t# ‚ö†Ô∏è Beware!! Those extra parentheses inside of the .from_tensor_slices() method matter enormously!!!\n",
    "\t\tdataset = tf.data.Dataset.from_tensor_slices(\n",
    "\t\t\t(\n",
    "\t\t\t\tdict(data_dataframe),\n",
    "\t\t\t\tlabel_dataframe\n",
    "\t\t\t)\n",
    "\t\t)\n",
    "\t\tif shuffle:\n",
    "\t\t\tdataset = dataset.shuffle(1000)\n",
    "\t\t# Split dataset into batches and repeat for as many epochs as requested:\n",
    "\t\tdataset = dataset.batch(batch_size).repeat(num_epochs)\n",
    "\t\treturn dataset\n",
    "\treturn input_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NB: Our input function generator has default values for number of epochs, shuffling, and batch size:\n",
    "training_input_function = make_input_function(training_dataframe, training_survived)\n",
    "\n",
    "# NB: For our testing function, we only need one epoch and no shuffling:\n",
    "testing_input_function = make_input_function(testing_dataframe, testing_survived, num_epochs=1, shuffle=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training our model\n",
    "\n",
    "Woo! ü•≥ We're about to train our first model!\n",
    "\n",
    "TensorFlow comes with a few core learning algorithms that are grouped into modules. In our case, we'll be using a linear classifier from the estimator module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\Julian\\AppData\\Local\\Temp\\tmpyyfc06w3\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\Julian\\\\AppData\\\\Local\\\\Temp\\\\tmpyyfc06w3', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\Julian\\AppData\\Local\\Temp\\tmpyyfc06w3\\model.ckpt.\n",
      "INFO:tensorflow:C:\\Users\\Julian\\AppData\\Local\\Temp\\tmpyyfc06w3\\model.ckpt-0.data-00000-of-00001\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:C:\\Users\\Julian\\AppData\\Local\\Temp\\tmpyyfc06w3\\model.ckpt-0.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:C:\\Users\\Julian\\AppData\\Local\\Temp\\tmpyyfc06w3\\model.ckpt-0.meta\n",
      "INFO:tensorflow:600\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 0.6931472, step = 0\n",
      "INFO:tensorflow:global_step/sec: 261.96\n",
      "INFO:tensorflow:loss = 0.4528076, step = 100 (0.383 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 200...\n",
      "INFO:tensorflow:Saving checkpoints for 200 into C:\\Users\\Julian\\AppData\\Local\\Temp\\tmpyyfc06w3\\model.ckpt.\n",
      "INFO:tensorflow:C:\\Users\\Julian\\AppData\\Local\\Temp\\tmpyyfc06w3\\model.ckpt-200.data-00000-of-00001\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:C:\\Users\\Julian\\AppData\\Local\\Temp\\tmpyyfc06w3\\model.ckpt-200.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:C:\\Users\\Julian\\AppData\\Local\\Temp\\tmpyyfc06w3\\model.ckpt-200.meta\n",
      "INFO:tensorflow:600\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 200...\n",
      "INFO:tensorflow:Loss for final step: 0.503338.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2023-01-30T16:10:04\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Julian\\AppData\\Local\\Temp\\tmpyyfc06w3\\model.ckpt-200\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.83447s\n",
      "INFO:tensorflow:Finished evaluation at 2023-01-30-16:10:05\n",
      "INFO:tensorflow:Saving dict for global step 200: accuracy = 0.74242425, accuracy_baseline = 0.625, auc = 0.82565045, auc_precision_recall = 0.7996961, average_loss = 0.4891844, global_step = 200, label/mean = 0.375, loss = 0.4820519, precision = 0.65656567, prediction/mean = 0.4289937, recall = 0.65656567\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 200: C:\\Users\\Julian\\AppData\\Local\\Temp\\tmpyyfc06w3\\model.ckpt-200\n",
      "\n",
      "------\n",
      "Result: {'accuracy': 0.74242425, 'accuracy_baseline': 0.625, 'auc': 0.82565045, 'auc_precision_recall': 0.7996961, 'average_loss': 0.4891844, 'label/mean': 0.375, 'loss': 0.4820519, 'precision': 0.65656567, 'prediction/mean': 0.4289937, 'recall': 0.65656567, 'global_step': 200}\n"
     ]
    }
   ],
   "source": [
    "# Create a linear estimator model:\n",
    "linear_estimator = tf.estimator.LinearClassifier(feature_columns=feature_columns)\n",
    "\n",
    "# Train our model, using our input function:\n",
    "linear_estimator.train(training_input_function)\n",
    "\n",
    "# Test/evaluate how good our model is with the data from our testing set, passed into the model by our training input function:\n",
    "result = linear_estimator.evaluate(testing_input_function)\n",
    "\n",
    "print('\\n------\\nResult:', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Julian\\AppData\\Local\\Temp\\tmpyyfc06w3\\model.ckpt-200\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "\n",
      "This person:\n",
      " sex                        female\n",
      "age                           8.0\n",
      "n_siblings_spouses              3\n",
      "parch                           1\n",
      "fare                       21.075\n",
      "class                       Third\n",
      "deck                      unknown\n",
      "embark_town           Southampton\n",
      "alone                           n\n",
      "Name: 6, dtype: object\n",
      "had a 0.58/1 probability of surviving\n"
     ]
    }
   ],
   "source": [
    "prediction = list(linear_estimator.predict(testing_input_function))\n",
    "print('\\nThis person:\\n', testing_dataframe.loc[6])\n",
    "print('had a %.2f/1 probability of surviving' % prediction[6]['probabilities'][1])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c4b873e07bceb12c2b9a42b36e7722015039dfeed477cfe3ebf1d2c97eb81cf7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
