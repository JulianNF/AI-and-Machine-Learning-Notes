{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine Learning with Tensor and Python\n",
    "===\n",
    "\n",
    "These are JulianNF's notes from following [freecodecamp's online Machine Learning with Python certification](https://www.freecodecamp.org/learn/machine-learning-with-python), and supplemented by [Google's Tensorflow documentation](https://www.tensorflow.org/guide/tensor)\n",
    "\n",
    "Feel free to benefit from them if you're studying on your own.\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification\n",
    "\n",
    "Where regression is used to predict a numeric value, classication is used to separate data points into classes of different labels.\n",
    "\n",
    "In this example, we'll use the Iris flower dataset to create a ML model for classifying flowers. It contains data for 3 different species of flowers:\n",
    "- Setosa\n",
    "- Versicolor\n",
    "- Virginica\n",
    "\n",
    "And for each flower:\n",
    "- sepal length\n",
    "- sepal width\n",
    "- petal length\n",
    "- petal width"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ðŸ“–ðŸ‘€ TODO - Research how classification algorithms work**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aside - Keras.io\n",
    "Keras is a human-oriented API and the most used deep learning framework. It's a module built on top of TensorFlow.\n",
    "\n",
    "It aims to make it easy to implement and test ML ideas by, among other things, abstracting and human-readability-ing many of the functionalities within TensorFlow."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepalLength  sepalWidth  petalLength  petalWidth  species\n",
      "0          6.4         2.8          5.6         2.2        2\n",
      "1          5.0         2.3          3.3         1.0        1\n",
      "2          4.9         2.5          4.5         1.7        2\n",
      "3          4.9         3.1          1.5         0.1        0\n",
      "4          5.7         3.8          1.7         0.3        0\n",
      "(120, 4)\n",
      "   sepalLength  sepalWidth  petalLength  petalWidth\n",
      "0          6.4         2.8          5.6         2.2\n",
      "1          5.0         2.3          3.3         1.0\n",
      "2          4.9         2.5          4.5         1.7\n",
      "3          4.9         3.1          1.5         0.1\n",
      "4          5.7         3.8          1.7         0.3\n"
     ]
    }
   ],
   "source": [
    "COLUMN_NAMES = [\n",
    "    'sepalLength',\n",
    "    'sepalWidth',\n",
    "    'petalLength',\n",
    "    'petalWidth',\n",
    "    'species'\n",
    "]\n",
    "SPECIES = [\n",
    "    'Setosa',\n",
    "    'Versicolor',\n",
    "    'Virginica'\n",
    "]\n",
    "\n",
    "training_file = tf.keras.utils.get_file(\n",
    "    \"iris_training.csv\",\n",
    "    \"https://storage.googleapis.com/download.tensorflow.org/data\"\n",
    ")\n",
    "testing_file = tf.keras.utils.get_file(\n",
    "    \"iris_testing.csv\",\n",
    "    \"https://storage.googleapis.com/download.tensorflow.org/data\"\n",
    ")\n",
    " \n",
    "training_df = pd.read_csv(training_file, names=COLUMN_NAMES, header=0)\n",
    "testing_df = pd.read_csv(testing_file, names=COLUMN_NAMES, header=0)\n",
    "\n",
    "print(training_df.head())\n",
    "\n",
    "training_species = training_df.pop('species')\n",
    "testing_species = testing_df.pop('species')\n",
    "\n",
    "print(training_df.shape)\n",
    "print(training_df.head())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NumericColumn(key='sepalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='sepalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='petalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='petalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_columns = []\n",
    "\n",
    "# NB: all the columns in our dataset are numeric, so we don't need to work with categorical columns and then numeric columns, we can simply reference all the columns names:\n",
    "for feature in training_df.keys():\n",
    "\tfeature_columns.append(\n",
    "\t\ttf.feature_column.numeric_column(key=feature)\n",
    "\t)\n",
    "feature_columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input function\n",
    "This time around, we'll write a basic input function (rather than an input-function-generating function like we did for the Titanic dataset) and later on, pass it to our model/TensorFlow using a lambda function.\n",
    "\n",
    "Lambda functions are anonymous functions in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(features_df, labels_df, training=True, batch_size=256):\n",
    "\tdataset = tf.data.Dataset.from_tensor_slices(\n",
    "\t\t(\n",
    "\t\t\tdict(features_df),\n",
    "\t\t\tlabels_df\n",
    "\t\t)\n",
    "\t)\n",
    "\tif training:\n",
    "\t\tdataset = dataset.shuffle(1000).repeat()\n",
    "\treturn dataset.batch(batch_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building and Training our model\n",
    "We first need to choose what type of model we want to apply. For classification tasks, there's a huge variety (100s?) of estimators/models in Tensorflow that we can pick from, such as:\n",
    "- `DNNClassifier` (deep neural network classifier)\n",
    "- `LinearClassifier`\n",
    "- ...\n",
    "\n",
    "We're going to use `DNNClassifier` because we may not be able to find a linear correspondance in our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\Julian\\AppData\\Local\\Temp\\tmpcajj3k2s\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\Julian\\\\AppData\\\\Local\\\\Temp\\\\tmpcajj3k2s', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "WARNING:tensorflow:From c:\\Users\\Julian\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\training_util.py:396: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From c:\\Users\\Julian\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adagrad.py:86: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\Julian\\AppData\\Local\\Temp\\tmpcajj3k2s\\model.ckpt.\n",
      "INFO:tensorflow:C:\\Users\\Julian\\AppData\\Local\\Temp\\tmpcajj3k2s\\model.ckpt-0.data-00000-of-00001\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:C:\\Users\\Julian\\AppData\\Local\\Temp\\tmpcajj3k2s\\model.ckpt-0.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:C:\\Users\\Julian\\AppData\\Local\\Temp\\tmpcajj3k2s\\model.ckpt-0.meta\n",
      "INFO:tensorflow:100\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 1.1988013, step = 0\n",
      "INFO:tensorflow:global_step/sec: 142.577\n",
      "INFO:tensorflow:loss = 1.0372792, step = 100 (0.703 sec)\n",
      "INFO:tensorflow:global_step/sec: 198.426\n",
      "INFO:tensorflow:loss = 1.01207, step = 200 (0.500 sec)\n",
      "INFO:tensorflow:global_step/sec: 198.082\n",
      "INFO:tensorflow:loss = 1.0026497, step = 300 (0.509 sec)\n",
      "INFO:tensorflow:global_step/sec: 180.804\n",
      "INFO:tensorflow:loss = 0.9938781, step = 400 (0.551 sec)\n",
      "INFO:tensorflow:global_step/sec: 178.316\n",
      "INFO:tensorflow:loss = 0.9772968, step = 500 (0.559 sec)\n",
      "INFO:tensorflow:global_step/sec: 195.677\n",
      "INFO:tensorflow:loss = 0.968427, step = 600 (0.510 sec)\n",
      "INFO:tensorflow:global_step/sec: 207.487\n",
      "INFO:tensorflow:loss = 0.96188986, step = 700 (0.485 sec)\n",
      "INFO:tensorflow:global_step/sec: 202.1\n",
      "INFO:tensorflow:loss = 0.9521224, step = 800 (0.490 sec)\n",
      "INFO:tensorflow:global_step/sec: 184.034\n",
      "INFO:tensorflow:loss = 0.9317946, step = 900 (0.545 sec)\n",
      "INFO:tensorflow:global_step/sec: 204.949\n",
      "INFO:tensorflow:loss = 0.9160131, step = 1000 (0.491 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.899\n",
      "INFO:tensorflow:loss = 0.9081792, step = 1100 (0.492 sec)\n",
      "INFO:tensorflow:global_step/sec: 203.72\n",
      "INFO:tensorflow:loss = 0.90341127, step = 1200 (0.499 sec)\n",
      "INFO:tensorflow:global_step/sec: 203.65\n",
      "INFO:tensorflow:loss = 0.8897512, step = 1300 (0.488 sec)\n",
      "INFO:tensorflow:global_step/sec: 191.86\n",
      "INFO:tensorflow:loss = 0.8900008, step = 1400 (0.520 sec)\n",
      "INFO:tensorflow:global_step/sec: 197.312\n",
      "INFO:tensorflow:loss = 0.876214, step = 1500 (0.503 sec)\n",
      "INFO:tensorflow:global_step/sec: 202.827\n",
      "INFO:tensorflow:loss = 0.8783884, step = 1600 (0.497 sec)\n",
      "INFO:tensorflow:global_step/sec: 204.596\n",
      "INFO:tensorflow:loss = 0.86274195, step = 1700 (0.490 sec)\n",
      "INFO:tensorflow:global_step/sec: 202.007\n",
      "INFO:tensorflow:loss = 0.84735036, step = 1800 (0.497 sec)\n",
      "INFO:tensorflow:global_step/sec: 198.973\n",
      "INFO:tensorflow:loss = 0.83901626, step = 1900 (0.496 sec)\n",
      "INFO:tensorflow:global_step/sec: 203.488\n",
      "INFO:tensorflow:loss = 0.8465172, step = 2000 (0.502 sec)\n",
      "INFO:tensorflow:global_step/sec: 195.591\n",
      "INFO:tensorflow:loss = 0.83583325, step = 2100 (0.505 sec)\n",
      "INFO:tensorflow:global_step/sec: 204.513\n",
      "INFO:tensorflow:loss = 0.8169911, step = 2200 (0.492 sec)\n",
      "INFO:tensorflow:global_step/sec: 202.922\n",
      "INFO:tensorflow:loss = 0.8163854, step = 2300 (0.493 sec)\n",
      "INFO:tensorflow:global_step/sec: 198.873\n",
      "INFO:tensorflow:loss = 0.81099594, step = 2400 (0.500 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.179\n",
      "INFO:tensorflow:loss = 0.7796643, step = 2500 (0.485 sec)\n",
      "INFO:tensorflow:global_step/sec: 197.931\n",
      "INFO:tensorflow:loss = 0.7964223, step = 2600 (0.513 sec)\n",
      "INFO:tensorflow:global_step/sec: 181.883\n",
      "INFO:tensorflow:loss = 0.7842498, step = 2700 (0.547 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.921\n",
      "INFO:tensorflow:loss = 0.7927314, step = 2800 (0.495 sec)\n",
      "INFO:tensorflow:global_step/sec: 192.36\n",
      "INFO:tensorflow:loss = 0.7801162, step = 2900 (0.520 sec)\n",
      "INFO:tensorflow:global_step/sec: 197.928\n",
      "INFO:tensorflow:loss = 0.76901174, step = 3000 (0.505 sec)\n",
      "INFO:tensorflow:global_step/sec: 186.673\n",
      "INFO:tensorflow:loss = 0.76312065, step = 3100 (0.540 sec)\n",
      "INFO:tensorflow:global_step/sec: 175.031\n",
      "INFO:tensorflow:loss = 0.7424598, step = 3200 (0.575 sec)\n",
      "INFO:tensorflow:global_step/sec: 193.1\n",
      "INFO:tensorflow:loss = 0.74772763, step = 3300 (0.515 sec)\n",
      "INFO:tensorflow:global_step/sec: 194.204\n",
      "INFO:tensorflow:loss = 0.73709166, step = 3400 (0.513 sec)\n",
      "INFO:tensorflow:global_step/sec: 202.022\n",
      "INFO:tensorflow:loss = 0.74309283, step = 3500 (0.493 sec)\n",
      "INFO:tensorflow:global_step/sec: 201.98\n",
      "INFO:tensorflow:loss = 0.73547935, step = 3600 (0.498 sec)\n",
      "INFO:tensorflow:global_step/sec: 202.086\n",
      "INFO:tensorflow:loss = 0.7178447, step = 3700 (0.493 sec)\n",
      "INFO:tensorflow:global_step/sec: 201.944\n",
      "INFO:tensorflow:loss = 0.72098434, step = 3800 (0.493 sec)\n",
      "INFO:tensorflow:global_step/sec: 204.759\n",
      "INFO:tensorflow:loss = 0.72500324, step = 3900 (0.495 sec)\n",
      "INFO:tensorflow:global_step/sec: 197.399\n",
      "INFO:tensorflow:loss = 0.7100158, step = 4000 (0.499 sec)\n",
      "INFO:tensorflow:global_step/sec: 200.104\n",
      "INFO:tensorflow:loss = 0.7102259, step = 4100 (0.498 sec)\n",
      "INFO:tensorflow:global_step/sec: 202.6\n",
      "INFO:tensorflow:loss = 0.689023, step = 4200 (0.499 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.009\n",
      "INFO:tensorflow:loss = 0.7061749, step = 4300 (0.503 sec)\n",
      "INFO:tensorflow:global_step/sec: 204.069\n",
      "INFO:tensorflow:loss = 0.68806124, step = 4400 (0.489 sec)\n",
      "INFO:tensorflow:global_step/sec: 201.089\n",
      "INFO:tensorflow:loss = 0.67825425, step = 4500 (0.500 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.711\n",
      "INFO:tensorflow:loss = 0.6741539, step = 4600 (0.498 sec)\n",
      "INFO:tensorflow:global_step/sec: 197.156\n",
      "INFO:tensorflow:loss = 0.6554389, step = 4700 (0.508 sec)\n",
      "INFO:tensorflow:global_step/sec: 198.801\n",
      "INFO:tensorflow:loss = 0.6589868, step = 4800 (0.500 sec)\n",
      "INFO:tensorflow:global_step/sec: 203.773\n",
      "INFO:tensorflow:loss = 0.65683645, step = 4900 (0.494 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 5000...\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into C:\\Users\\Julian\\AppData\\Local\\Temp\\tmpcajj3k2s\\model.ckpt.\n",
      "INFO:tensorflow:C:\\Users\\Julian\\AppData\\Local\\Temp\\tmpcajj3k2s\\model.ckpt-5000.data-00000-of-00001\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:C:\\Users\\Julian\\AppData\\Local\\Temp\\tmpcajj3k2s\\model.ckpt-5000.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:C:\\Users\\Julian\\AppData\\Local\\Temp\\tmpcajj3k2s\\model.ckpt-5000.meta\n",
      "INFO:tensorflow:100\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 5000...\n",
      "INFO:tensorflow:Loss for final step: 0.6220372.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifierV2 at 0x19ab2d55ee0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_classifier = tf.estimator.DNNClassifier(\n",
    "    feature_columns=feature_columns,\n",
    "\t# The shape of our neural net --> 30 nodes in first layer, 10 in the second layer\n",
    "    hidden_units=[30, 10],\n",
    "\t# for the three flower classes that we know are in our input data\n",
    "    n_classes=3\n",
    ")\n",
    "\n",
    "dnn_classifier.train(\n",
    "\t# We use an anonymous function, aka a 'lambda function' in Python here because we didn't embed our input function within a \"input function maker\", as we did in our Titanic example:\n",
    "\tinput_fn=lambda: input_fn(training_df, training_species, training=True),\n",
    "\t# Go through dataset until 5000 \"things\"(?) have been looked at:\n",
    "\tsteps=5000\n",
    ")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2023-02-02T10:01:19\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Julian\\AppData\\Local\\Temp\\tmpcajj3k2s\\model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 2.44823s\n",
      "INFO:tensorflow:Finished evaluation at 2023-02-02-10:01:22\n",
      "INFO:tensorflow:Saving dict for global step 5000: accuracy = 0.8333333, average_loss = 0.6464407, global_step = 5000, loss = 0.6464407\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: C:\\Users\\Julian\\AppData\\Local\\Temp\\tmpcajj3k2s\\model.ckpt-5000\n",
      "{'accuracy': 0.8333333, 'average_loss': 0.6464407, 'loss': 0.6464407, 'global_step': 5000}\n"
     ]
    }
   ],
   "source": [
    "evaluation = dnn_classifier.evaluate(\n",
    "\tinput_fn= lambda: input_fn(testing_df, testing_species, training=False)\n",
    ")\n",
    "\n",
    "print(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using our model\n",
    "Now that we've created a model, we can use it to predict individual cases.\n",
    "\n",
    "For this, we'll:\n",
    "1. create an input function without labels (after all, we want the model to tell us what it thinks the label is),\n",
    "2. ask for the user to input their values (presumably from field observations in this case)\n",
    "3. use our trained model to predict what flower species is\n",
    "\t- Note that by looking at each (in our case only one) prediction (the `pred_dict` value in our code below), we can see to what extent/percent the model thinks that our output matches each of the possible labels we trained it with (i.e. Setosa, Versicolor, Virginica)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Please input values for the following flower features:\n",
      "\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Julian\\AppData\\Local\\Temp\\tmpcajj3k2s\\model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "{'logits': array([ 1.3364276, -3.3479393,  0.6834881], dtype=float32), 'probabilities': array([0.6537007 , 0.00603927, 0.34026003], dtype=float32), 'class_ids': array([0], dtype=int64), 'classes': array([b'0'], dtype=object), 'all_class_ids': array([0, 1, 2]), 'all_classes': array([b'0', b'1', b'2'], dtype=object)}\n",
      "Prediction is \"Setosa\" (65.4%)\n"
     ]
    }
   ],
   "source": [
    "def prediction_input_fn(features, batch_size=256):\n",
    "\treturn tf.data.Dataset.from_tensor_slices(dict(features)).batch(batch_size)\n",
    "\n",
    "\n",
    "def get_user_input():\n",
    "    user_input = {}\n",
    "    print('\\nPlease input values for the following flower features:\\n')\n",
    "    for feature in training_df.keys():\n",
    "        valid = True\n",
    "        while valid:\n",
    "            value = input(feature + ': ')\n",
    "            if not value.isdigit():\n",
    "                valid = False\n",
    "\t\t# Why is the value stored as an array?:\n",
    "        user_input[feature] = [float(value)]\n",
    "    return user_input\n",
    "\n",
    "\n",
    "def predict_species():\n",
    "\tuser_input = get_user_input()\n",
    "\t\n",
    "\tpredictions = dnn_classifier.predict(\n",
    "        input_fn=lambda: prediction_input_fn(user_input)\n",
    "    )\n",
    "\t\n",
    "\tfor pred_dict in predictions:\n",
    "\t\tprint(pred_dict)\n",
    "\t\tclass_id = pred_dict['class_ids'][0]\n",
    "\t\tprobability = pred_dict['probabilities'][class_id]\n",
    "\t\t\n",
    "\t\tprint('Prediction is \"{}\" ({:.1f}%)'.format(\n",
    "\t\t\tSPECIES[class_id], 100*probability\n",
    "\t\t\t)\n",
    "\t\t)\n",
    "\n",
    "predict_species()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c4b873e07bceb12c2b9a42b36e7722015039dfeed477cfe3ebf1d2c97eb81cf7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
